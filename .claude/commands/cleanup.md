---
name: cleanup
description: Python ä»£ç å†—ä½™æ£€æµ‹æ¸…å•
version: 0.0.1
tags:
  - python
  - cleanup
  - redundancy
  - code-quality
dependencies:
  grep: "any"
---

# Python ä»£ç å†—ä½™æ£€æµ‹

> **å…ˆçœ‹æœ‰ä»€ä¹ˆï¼Œå†çœ‹å†™ä»€ä¹ˆ**

æ£€æµ‹ä»£ç ä¸­æ˜¯å¦æœ‰å¯ç”¨æ ‡å‡†åº“æˆ–å·²å®‰è£…åŒ…æ›¿ä»£çš„å†—ä½™å®ç°ã€‚

---

## å¿«æ·å‘½ä»¤

```bash
/cleanup              # æ˜¾ç¤ºå®Œæ•´æ¸…å•
/cleanup scan         # æ‰§è¡Œå¿«é€Ÿæ‰«æ
/cleanup <pattern>    # æŸ¥çœ‹ç‰¹å®šæ¨¡å¼è¯¦æƒ…
```

---

## æ ¸å¿ƒåŸåˆ™

| åŸåˆ™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–ä¼˜å…ˆ** | æ£€æŸ¥ `uv.lock`ï¼Œä¼˜å…ˆç”¨å·²å®‰è£…çš„åŒ… |
| **æ ‡å‡†åº“ä¼˜å…ˆ** | Python å†…ç½®åŠŸèƒ½æ— éœ€å®‰è£… |
| **å£°æ˜å³å­˜åœ¨** | `pyproject.toml` ä¸­å£°æ˜çš„å°±æ˜¯å¯ç”¨çš„ |
| **åˆ é™¤è€Œéå…¼å®¹** | ä¸ä¿ç•™"ä»¥é˜²ä¸‡ä¸€"çš„æ—§ä»£ç  |

---

## å†—ä½™æ¨¡å¼å¯¹ç…§è¡¨

| å½“å‰æ¨¡å¼ | åº”è¯¥ç”¨ | æ£€æµ‹å‘½ä»¤ |
|----------|--------|----------|
| `os.path.join` | `pathlib.Path` | `grep -rn "os.path\."` |
| `class X: def __init__` | `@dataclass` | `grep -rn "def __init__"` |
| `urllib.request` | `requests` | `grep -rn "urllib"` |
| `datetime.strptime` | `dateutil.parser` | `grep -rn "strptime"` |
| `csv.reader/open` | `pandas.read_csv` | `grep -rn "csv\\.reader\|open.*\\.csv"` |
| `try: finally: close()` | `contextlib` | `grep -rn "finally:.*close"` |

---

## æ¨¡å¼è¯¦è§£

### 1. pathlib æ›¿ä»£ os.path

**é—®é¢˜**ï¼š`os.path` æ“ä½œç¹çï¼Œä¸æ”¯æŒé“¾å¼è°ƒç”¨

```python
# âŒ å†—ä½™
import os
path = os.path.join("data", "files", "test.txt")
if os.path.exists(path):
    with open(path) as f:
        content = f.read()

# âœ… æ¨è
from pathlib import Path
path = Path("data") / "files" / "test.txt"
if path.exists():
    content = path.read_text()
```

**æ£€æµ‹**ï¼š
```bash
grep -rn "os\.path\." src/
```

**æ›¿æ¢åœºæ™¯**ï¼š
- `os.path.join` â†’ `Path() / "file"`
- `os.path.exists` â†’ `.exists()`
- `os.path.dirname` â†’ `.parent`
- `os.path.basename` â†’ `.name`
- `os.path.splitext` â†’ `.stem` / `.suffix`

---

### 2. dataclasses æ›¿ä»£æ‰‹åŠ¨ __init__

**é—®é¢˜**ï¼šé‡å¤ç¼–å†™ `__init__`ã€`__repr__`ã€`__eq__`

```python
# âŒ å†—ä½™
class User:
    def __init__(self, name: str, age: int, email: str):
        self.name = name
        self.age = age
        self.email = email
    def __repr__(self):
        return f"User(name={self.name}, age={self.age}, email={self.email})"
    def __eq__(self, other):
        if not isinstance(other, User):
            return False
        return (self.name, self.age, self.email) == (other.name, other.age, other.email)

# âœ… æ¨è
from dataclasses import dataclass

@dataclass
class User:
    name: str
    age: int
    email: str
```

**æ£€æµ‹**ï¼š
```bash
# æŸ¥æ‰¾ç®€å•æ•°æ®å®¹å™¨ç±»ï¼ˆå¤šä¸ª self.xxx = xxxï¼‰
grep -Pn "class \w+.*:.*\n    def __init__" src/*.py | head -20
```

**é€‚ç”¨ä¿¡å·**ï¼š
- ç±»ä¸»è¦æ˜¯æ•°æ®å®¹å™¨
- `__init__` åªåšå±æ€§èµ‹å€¼
- éœ€è¦ `__repr__` æˆ– `__eq__`

---

### 3. requests æ›¿ä»£ urllib

**é—®é¢˜**ï¼š`urllib` API å¤æ‚ï¼Œé”™è¯¯å¤„ç†ç¹ç

```python
# âŒ å†—ä½™
import urllib.request
import urllib.parse
import json

url = "https://api.example.com/users"
data = json.dumps({"name": "Alice"}).encode()
req = urllib.request.Request(url, data=data, headers={"Content-Type": "application/json"})
try:
    with urllib.request.urlopen(req) as response:
        result = json.loads(response.read().decode())
except urllib.error.HTTPError as e:
    print(f"Error: {e.code}")

# âœ… æ¨è
import requests

response = requests.post("https://api.example.com/users", json={"name": "Alice"})
result = response.json()  # è‡ªåŠ¨å¤„ç† JSON
```

**æ£€æµ‹**ï¼š
```bash
grep -rn "urllib\." src/
```

**æ›¿æ¢åœºæ™¯**ï¼š
- `urllib.request.urlopen` â†’ `requests.get/post/put/delete`
- `urllib.parse.urlencode` â†’ `requests` è‡ªåŠ¨å¤„ç†
- æ‰‹åŠ¨ JSON å¤„ç† â†’ `json=` å‚æ•°

---

### 4. dateutil æ›¿ä»£ strptime

**é—®é¢˜**ï¼š`strptime` éœ€è¦é¢„çŸ¥æ ¼å¼ï¼Œæ— æ³•å¤„ç†å¤šç§æ ¼å¼

```python
# âŒ å†—ä½™
from datetime import datetime

# å¿…é¡»æŒ‡å®šæ ¼å¼
dt = datetime.strptime("2024-01-15", "%Y-%m-%d")
dt2 = datetime.strptime("15/01/2024", "%d/%m/%Y")  # ä¸åŒæ ¼å¼éœ€è¦ä¸åŒè§£æ

# âœ… æ¨è
from dateutil import parser

# è‡ªåŠ¨è¯†åˆ«æ ¼å¼
dt = parser.parse("2024-01-15")
dt2 = parser.parse("15/01/2024")
dt3 = parser.parse("January 15, 2024")
```

**æ£€æµ‹**ï¼š
```bash
grep -rn "\.strptime" src/
```

**é€‚ç”¨åœºæ™¯**ï¼š
- è§£æç”¨æˆ·è¾“å…¥çš„æ—¥æœŸ
- å¤„ç†å¤šç§æ—¥æœŸæ ¼å¼
- ä¸ç¡®å®šå…·ä½“æ ¼å¼

---

### 5. pandas æ›¿ä»£æ‰‹åŠ¨ CSV å¤„ç†

**é—®é¢˜**ï¼šæ‰‹åŠ¨å¤„ç† CSV ä»£ç å†—é•¿ï¼Œæ˜“å‡ºé”™

```python
# âŒ å†—ä½™
import csv

data = []
with open("data.csv") as f:
    reader = csv.DictReader(f)
    for row in reader:
        data.append({"name": row["name"], "value": float(row["value"])})

# ç­›é€‰ã€èšåˆéœ€è¦æ›´å¤šä»£ç ...

# âœ… æ¨è
import pandas as pd

df = pd.read_csv("data.csv")
filtered = df[df["value"] > 100]  # ä¸€è¡Œæå®š
result = df.groupby("category")["value"].sum()
```

**æ£€æµ‹**ï¼š
```bash
grep -rn "csv\.reader\|csv\.DictReader\|open.*\.csv" src/
```

**é€‚ç”¨åœºæ™¯**ï¼š
- éœ€è¦ç­›é€‰/èšåˆ/è½¬æ¢æ•°æ®
- CSV æ–‡ä»¶è¾ƒå¤§
- éœ€è¦æ•°æ®åˆ†æ

**ä¸é€‚åœºæ™¯**ï¼š
- ç®€å•è¯»å†™ï¼ˆç”¨ `csv` æ¨¡å—æ›´è½»é‡ï¼‰
- æµå¼å¤„ç†å¤§æ–‡ä»¶ï¼ˆpandas éœ€è¦å…¨éƒ¨åŠ è½½ï¼‰

---

### 6. contextlib æ›¿ä»£ try-finally

**é—®é¢˜**ï¼š`try-finally` æ ·æ¿ä»£ç å¤š

```python
# âŒ å†—ä½™
f = open("file.txt")
try:
    data = f.read()
    # å¤„ç†æ•°æ®
finally:
    f.close()

# âœ… æ¨è
from contextlib import ExitStack

with open("file.txt") as f:
    data = f.read()
    # è‡ªåŠ¨å…³é—­
```

**æ£€æµ‹**ï¼š
```bash
grep -rn "finally:" src/ | grep -i "close\|cleanup"
```

**é€‚ç”¨åœºæ™¯**ï¼š
- èµ„æºæ¸…ç†ï¼ˆæ–‡ä»¶ã€é”ã€è¿æ¥ï¼‰
- éœ€è¦ç®¡ç†å¤šä¸ªèµ„æºï¼ˆç”¨ `ExitStack`ï¼‰

---

## å¿«é€Ÿæ‰«æ

### ä¸€é”®æ‰«ææ‰€æœ‰æ¨¡å¼

```bash
# åˆ›å»ºæ‰«æè„šæœ¬
cat > scan_redundancy.sh << 'EOF'
#!/bin/bash
echo "ğŸ” æ‰«æä»£ç å†—ä½™..."
echo ""
echo "1ï¸âƒ£ os.path æ¨¡å¼ï¼š"
grep -rn "os\.path\." src/ 2>/dev/null || echo "  âœ… æœªå‘ç°"
echo ""
echo "2ï¸âƒ£ urllib æ¨¡å¼ï¼š"
grep -rn "urllib\." src/ 2>/dev/null || echo "  âœ… æœªå‘ç°"
echo ""
echo "3ï¸âƒ£ strptime æ¨¡å¼ï¼š"
grep -rn "\.strptime" src/ 2>/dev/null || echo "  âœ… æœªå‘ç°"
echo ""
echo "4ï¸âƒ£ csv æ¨¡å¼ï¼š"
grep -rn "csv\.reader\|csv\.DictReader" src/ 2>/dev/null || echo "  âœ… æœªå‘ç°"
echo ""
echo "5ï¸âƒ£ finally close æ¨¡å¼ï¼š"
grep -rn "finally:" src/ | grep -i "close" 2>/dev/null || echo "  âœ… æœªå‘ç°"
echo ""
echo "6ï¸âƒ£ æ‰‹åŠ¨ __init__ æ¨¡å¼ï¼š"
grep -Pn "class \w+.*:.*\n    def __init__" src/*.py 2>/dev/null | head -5 || echo "  âœ… æœªå‘ç°"
EOF

chmod +x scan_redundancy.sh
./scan_redundancy.sh
```

### æŒ‰æ¨¡å¼æ‰«æ

```bash
# æ£€æŸ¥ uv.lock ä¸­å·²å®‰è£…çš„åŒ…
grep -A 100 "dependencies = \[" uv.lock | grep 'name = ' | cut -d'"' -f2

# åªæ£€æŸ¥å·²å®‰è£…åŒ…ç›¸å…³çš„å†—ä½™
if grep -q "requests" uv.lock; then
    echo "ğŸ“¦ å·²å®‰è£… requestsï¼Œæ£€æŸ¥ urllib..."
    grep -rn "urllib" src/
fi
```

---

## å®Œæ•´ç¤ºä¾‹

### åœºæ™¯ï¼šé‡æ„ API å®¢æˆ·ç«¯

**Before**ï¼ˆå†—ä½™ï¼‰ï¼š
```python
import urllib.request
import json
from datetime import datetime

class APIClient:
    def __init__(self, base_url: str, timeout: int):
        self.base_url = base_url
        self.timeout = timeout

    def get_user(self, user_id: int):
        url = f"{self.base_url}/users/{user_id}"
        req = urllib.request.Request(url)
        try:
            with urllib.request.urlopen(req, timeout=self.timeout) as response:
                data = json.loads(response.read().decode())
                user = data["user"]
                user["created_at"] = datetime.strptime(user["created_at"], "%Y-%m-%d")
                return user
        except urllib.error.HTTPError as e:
            return None
```

**After**ï¼ˆæ¸…ç†åï¼‰ï¼š
```python
import requests
from dateutil import parser
from dataclasses import dataclass
from typing import Optional

@dataclass
class User:
    id: int
    name: str
    email: str
    created_at: datetime

class APIClient:
    def __init__(self, base_url: str, timeout: int = 30):
        self.base_url = base_url.rstrip("/")
        self.timeout = timeout

    def get_user(self, user_id: int) -> Optional[User]:
        response = requests.get(
            f"{self.base_url}/users/{user_id}",
            timeout=self.timeout
        )
        response.raise_for_status()
        data = response.json()["user"]
        data["created_at"] = parser.parse(data["created_at"])
        return User(**data)
```

**æ”¹è¿›**ï¼š
- `urllib` â†’ `requests`ï¼ˆæ›´ç®€æ´ï¼‰
- `datetime.strptime` â†’ `dateutil.parser.parse`ï¼ˆè‡ªåŠ¨è¯†åˆ«æ ¼å¼ï¼‰
- æ‰‹åŠ¨ `__init__` â†’ `@dataclass`ï¼ˆè‡ªåŠ¨ç”Ÿæˆ `__repr__`ã€`__eq__`ï¼‰
- æ·»åŠ ç±»å‹æç¤ºï¼ˆ`Optional[User]`ï¼‰

---

## å·¥å…·æ¨è

| å·¥å…· | ç”¨é€” | å®‰è£… |
|------|------|------|
| **ruff** | Lint & Format | `uv add ruff` |
| **mypy** | ç±»å‹æ£€æŸ¥ | `uv add mypy` |
| **grep** | æ¨¡å¼æœç´¢ | ç³»ç»Ÿè‡ªå¸¦ |

---

**å†™ä»£ç å‰å…ˆçœ‹ `uv.lock`**
